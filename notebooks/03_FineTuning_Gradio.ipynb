{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMa4R7Pf5YTigJx9nMuKVTp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/a-00-a/IdolFan-LLM-Chatbot-Korean-Entertainment-Domain/blob/main/notebooks/03_FineTuning_Gradio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KI3KiEnyudPe"
      },
      "outputs": [],
      "source": [
        "# 02 dataset 생성 코드 추가 -> 03에서 단독 실행 가능\n",
        "# 라이브러리 import\n",
        "from datasets import Dataset\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForCausalLM,\n",
        "    Trainer,\n",
        "    TrainingArguments\n",
        ")\n",
        "from peft import LoraConfig, get_peft_model\n",
        "import torch\n",
        "import gradio as gr\n",
        "\n",
        "# sample 데이터 (단일문장, 20개)\n",
        "sample_data = [\n",
        "    {\"prompt\": \"오늘 기분 어때요?\", \"completion\": \"팬들 생각하면서 힘냈어요!\"},\n",
        "    {\"prompt\": \"추천 노래 있어요?\", \"completion\": \"제 최애 노래는 'Shakira-Zoo'예요!\"},\n",
        "    {\"prompt\": \"오늘 뭐했어요?\", \"completion\": \"새로운 앨범 춤 연습했어요! 기대해주세요\"},\n",
        "    {\"prompt\": \"최근 좋아하는 영화는?\", \"completion\": \"최근에는 'Inception'봤는데 재밌었어요. 추천합니당!\"},\n",
        "    {\"prompt\": \"팬들에게 한마디?\", \"completion\": \"항상 사랑해요!\"},\n",
        "    {\"prompt\": \"새로운 앨범 언제 나오나요?\", \"completion\": \"조금만 더 기다려주세요! 곧 만나요.\"},\n",
        "    {\"prompt\": \"운동도 하나요?\", \"completion\": \"네, 건강하게 유지하려고 해요.\"},\n",
        "    {\"prompt\": \"오늘 날씨 어때요?\", \"completion\": \"오늘 많이 춥네요. 따뜻하게 입구 다니세요!\"},\n",
        "    {\"prompt\": \"좋아하는 음식은?\", \"completion\": \"초밥 좋아해요!\"},\n",
        "    {\"prompt\": \"휴식 시간에는 뭐해요?\", \"completion\": \"책 읽거나 음악 들어요. 그리고 팬들 생각도!!\"},\n",
        "    {\"prompt\": \"팬들 질문 많이 받았나요?\", \"completion\": \"네, 항상 감사하게 받아요.\"},\n",
        "    {\"prompt\": \"최근 목표는?\", \"completion\": \"더 좋은 음악 만들기!\"},\n",
        "    {\"prompt\": \"노래 연습 어떻게 하나요?\", \"completion\": \"매일매일 꾸준히 연습해요.\"},\n",
        "    {\"prompt\": \"팬들과 소통 방법?\", \"completion\": \"인스타랑 bubble로 소통해요!\"},\n",
        "    {\"prompt\": \"좋아하는 운동?\", \"completion\": \"요가랑 가벼운 러닝 좋아해요.\"},\n",
        "    {\"prompt\": \"가장 기억에 남는 순간?\", \"completion\": \"저번 콘서트에서 팬들과 노래부른 순간이 감동이였어요!\"},\n",
        "    {\"prompt\": \"추천하는 책?\", \"completion\": \"'Harry Potter' 시리즈 좋아해요. 완전 강추!!\"},\n",
        "    {\"prompt\": \"스트레스 해소 방법?\", \"completion\": \"노래하거나 춤추면서 풀어요. 그리구 엽떡먹기..?ㅋㅋㅋ\"},\n",
        "    {\"prompt\": \"최근 관심 있는 것?\", \"completion\": \"젤리에 푹 빠져서 포도맛 젤리! 입니다\"},\n",
        "    {\"prompt\": \"팬들에게 전하고 싶은 말?\", \"completion\": \"늘 함께 해줘서 고마워요!\"},\n",
        "]\n",
        "\n",
        "# Tokenizer 로드\n",
        "model_name = \"skt/kogpt2-base-v2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "tokenizer.pad_token = tokenizer.eos_token  # padding token 정의\n",
        "\n",
        "# tokenize 함수 (batched=False, 단일 example 방지)\n",
        "def tokenize(example):\n",
        "    text = example[\"prompt\"] + \" \" + example[\"completion\"]\n",
        "    tokenized = tokenizer(\n",
        "        text,\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=128\n",
        "    )\n",
        "    # labels 생성\n",
        "    labels = tokenized[\"input_ids\"].copy()\n",
        "\n",
        "    # pad_token_id는 -100으로 바꾸기 (Loss 무시)\n",
        "    labels = [i if i != tokenizer.pad_token_type_id else -100 for i in labels]\n",
        "\n",
        "    tokenized[\"labels\"] = labels\n",
        "    return tokenized\n",
        "\n",
        "# Dataset 생성\n",
        "dataset = Dataset.from_list(sample_data)\n",
        "tokenized_dataset = dataset.map(tokenize, batched=False)\n",
        "tokenized_dataset = tokenized_dataset.remove_columns([\"prompt\", \"completion\"])\n",
        "tokenized_dataset.set_format(\"torch\")\n",
        "print(tokenized_dataset.column_names)\n",
        "\n",
        "#모델 로드 + LoRA 설정\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "lora_config = LoraConfig(\n",
        "    r=8,\n",
        "    lora_alpha=16,\n",
        "    target_modules=[\"c_attn\"],\n",
        "    lora_dropout=0.1,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\"\n",
        ")\n",
        "model = get_peft_model(model, lora_config)\n",
        "model.print_trainable_parameters()\n",
        "\n",
        "# Training 설정 (wandb off)\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./idolfan_lora\",\n",
        "    num_train_epochs=1,\n",
        "    per_device_train_batch_size=2,\n",
        "    logging_steps=1,\n",
        "    save_steps=50,\n",
        "    save_total_limit=3,\n",
        "    learning_rate=5e-4,\n",
        "    fp16=torch.cuda.is_available(),\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset, # 02 에서 만든 dataset\n",
        ")\n",
        "\n",
        "# 학습 시작\n",
        "trainer.train()\n",
        "\n",
        "# Gradio 챗봇\n",
        "def chatbot(prompt):\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "    outputs = model.generate(\n",
        "        **inputs,\n",
        "        max_length=50,\n",
        "        do_sample=True,\n",
        "        top_p=0.9,\n",
        "        temperature=0.8\n",
        "    )\n",
        "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "gr.Interface(\n",
        "    fn=chatbot,\n",
        "    inputs=\"text\",\n",
        "    outputs=\"text\",\n",
        "    title=\"Idol Fan Chatbot\",\n",
        "    description=\"LoRA fine-tuned idol-style chatbot\"\n",
        ").launch()\n"
      ]
    }
  ]
}