# Content-Aware LLM pipeline

## Overview
This project explores fine-tuning and open-source LLM for content generation tasks using domain-specific text data.

## Motivation
How domain knowledge can improve generation quality in content-oriented services.

## Dataset
-Data source
-Design rationale
-Preprocessing steps

## Model & Training
-Base model
-Fine-tuning method (LoRA)
-Training setup

## Evaluation
-Baseline vs Fine-tuned comparison
-Qualitative analysis

## Deployment
-Gradio interface
-Inference examples

## Notes on LLM Trends
-Recent research insights
-Applicability to real services

## π“‚ Day 1 : ν™κ²½ μ„¤μ •
- GPU ν™•μΈ λ° ν™κ²½ μ„Έν…
- transformer, torch, datasets import λ° λ²„μ „ ν™•μΈ
- Colab Notebook: [Day1] (https://colab.research.google.com/github/a-00-a/LLM_Practice/blob/main/day1_environment_setup.ipynb)

## π“‚ Day 2 : λ°μ΄ν„°μ…‹ νμ΄ν”„λΌμΈ
- Hugging Face Dataset λ΅λ”©
- ν…μ¤νΈ μ •μ  λ° ν† ν¬λ‚μ΄μ§•
- Colab Notebook: [Day2] (https://colab.research.google.com/github/a-00-a/LLM_Practice/blob/main/day2_dataset_pipeline.ipynb) 
